{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa5a28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Shape: (23481, 4)\n",
      "Real News Shape: (21417, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fake = pd.read_csv(\"Fake.csv\")\n",
    "real = pd.read_csv(\"True.csv\")\n",
    "\n",
    "print(\"Fake News Shape:\", fake.shape)\n",
    "print(\"Real News Shape:\", real.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be119d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Data Shape: (44898, 5)\n",
      "                                               title  \\\n",
      "0  “LITTLE” MARCO RUBIO GRILLS Trump’s Secretary ...   \n",
      "1  BEST EVER CROOKED HILLARY Collection Of Lies A...   \n",
      "2  MEGYN KELLY Not Exactly Getting Warm Welcome A...   \n",
      "3  White House supports renewal of spy law withou...   \n",
      "4  Factbox: Trump on Twitter (July 11) - Mississi...   \n",
      "\n",
      "                                                text       subject  \\\n",
      "0                                                         politics   \n",
      "1  Hillary Clinton has had a loooong career at ly...      politics   \n",
      "2  NBC is canceling the third hour of  Today  to ...      politics   \n",
      "3  WASHINGTON (Reuters) - The Trump administratio...  politicsNews   \n",
      "4  The following statements were posted to the ve...  politicsNews   \n",
      "\n",
      "             date  label  \n",
      "0    Jan 11, 2017      0  \n",
      "1    May 28, 2016      0  \n",
      "2    Jan 27, 2017      0  \n",
      "3  March 1, 2017       1  \n",
      "4  July 12, 2017       1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add labels\n",
    "fake[\"label\"] = 0\n",
    "real[\"label\"] = 1\n",
    "\n",
    "# Combine\n",
    "data = pd.concat([fake, real])\n",
    "\n",
    "# Shuffle\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Check shape\n",
    "print(\"Combined Data Shape:\", data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "066cb322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                     \n",
      "1    hillary clinton loooong career lying twisting ...\n",
      "2    nbc canceling third hour today make way new st...\n",
      "3    washington reuters trump administration want r...\n",
      "4    following statement posted verified twitter ac...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "data[\"text\"] = data[\"text\"].apply(clean_text)\n",
    "print(data[\"text\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f9b1e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9485523385300668\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      4703\n",
      "           1       0.93      0.97      0.95      4277\n",
      "\n",
      "    accuracy                           0.95      8980\n",
      "   macro avg       0.95      0.95      0.95      8980\n",
      "weighted avg       0.95      0.95      0.95      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X = data[\"text\"]\n",
    "y = data[\"label\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a339e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_news(news_text):\n",
    "    # Step 1: Text ko vector mein badlo (same vectorizer use karo)\n",
    "    transformed_text = vectorizer.transform([news_text])\n",
    "    \n",
    "    # Step 2: Predict karo\n",
    "    prediction = model.predict(transformed_text)\n",
    "\n",
    "    # Step 3: Output dikhayo\n",
    "    if prediction[0] == 0:\n",
    "        print(\"❌ This news is FAKE\")\n",
    "    else:\n",
    "        print(\"✅ This news is REAL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0db75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ This news is REAL\n"
     ]
    }
   ],
   "source": [
    "predict_news(\"NASA has confirmed the discovery of a new habitable planet.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d89e773b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ This news is REAL\n",
      "✅ This news is REAL\n",
      "✅ This news is REAL\n"
     ]
    }
   ],
   "source": [
    "predict_news(\"Pakistan wins the FIFA World Cup 2026.\")\n",
    "predict_news(\"Apple announces iPhone 20 with teleportation feature.\")\n",
    "predict_news(\"Government launches AI-powered education system in public schools.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85c189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
